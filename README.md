# PredicciÃ³n de Actividad Comercial en Madrid

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Production-green.svg)](https://github.com/alexandrobg/madrid-commercial-prediction)

## Resumen Ejecutivo

Este proyecto implementa un sistema de Machine Learning para predecir la inactividad de locales comerciales en Madrid, utilizando datos administrativos del Ayuntamiento de Madrid (2020-2024) enriquecidos con indicadores socioeconÃ³micos. El modelo principal (MLP) alcanza una precisiÃ³n del 88.48% y un AUC de 0.854, proporcionando una herramienta robusta para la toma de decisiones en planificaciÃ³n urbana y polÃ­tica comercial.

## DescripciÃ³n del Proyecto

### Contexto y MotivaciÃ³n

Madrid, como capital econÃ³mica de EspaÃ±a, concentra mÃ¡s de 60,000 establecimientos comerciales que emplean directamente a mÃ¡s de 305,000 personas. Sin embargo, eventos como la pandemia COVID-19 y cambios en los patrones de consumo han generado cierres comerciales desiguales segÃºn ubicaciÃ³n y sector. Este proyecto aborda la necesidad de anticipar estos cierres para optimizar polÃ­ticas pÃºblicas y decisiones de inversiÃ³n privada.

### CaracterÃ­sticas TÃ©cnicas

- **Dataset**: 8.3+ millones de registros histÃ³ricos (2020-2024)
- **Variables**: GeolocalizaciÃ³n, clasificaciÃ³n CNAE, tipo de acceso, renta per cÃ¡pita, poblaciÃ³n
- **MetodologÃ­a**: SEMMA (SAS Enterprise Miner) con validaciÃ³n temporal
- **Modelos**: 9 algoritmos diferentes con optimizaciÃ³n de hiperparÃ¡metros
- **Interpretabilidad**: AnÃ¡lisis SHAP para explicabilidad del modelo

## Resultados Principales

### Rendimiento de Modelos (Conjunto de Test 2024)

| Modelo | AUC | F1-Score | Accuracy | CaracterÃ­sticas |
|--------|-----|----------|----------|----------------|
| **MLP** | **0.8540** | **0.9253** | **0.8848** | Mejor equilibrio global; seleccionado por parsimonia |
| VotingClassifier | 0.8541 | 0.9242 | 0.8828 | Ensamble robusto (RF + XGB + MLP) |
| Random Forest | 0.8489 | 0.9250 | 0.8841 | Alto recall; interpretable |
| XGBoost | 0.8491 | 0.9151 | 0.8673 | Buen AUC; conservador en especificidad |
| RegresiÃ³n LogÃ­stica | 0.8475 | 0.9253 | 0.8848 | Baseline sÃ³lido y estable |

### Variables MÃ¡s Influyentes (AnÃ¡lisis SHAP)

1. **desc_seccion_sin_actividad** â€” Indicador de falta de actividad (impacto negativo)
2. **desc_tipo_acceso_local_puerta_calle** â€” Acceso directo desde calle (impacto positivo)
3. **Renta_Media** â€” Renta media del distrito (mayor renta â†’ mayor actividad)
4. **Total_Poblacion** â€” PoblaciÃ³n del barrio (impacto positivo moderado)
5. **desc_seccion_hosteleria** â€” Presencia del sector hostelerÃ­a (impacto positivo)

## Arquitectura del Proyecto

```
madrid-commercial-prediction/
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ TFM-Alexandro Bazan Guardia.pdf
â”œâ”€â”€ VERIFICATION.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ variables_boruta.txt
â”œâ”€â”€ variables_rfecv.txt
â”œâ”€â”€ variables_sbf.txt
â”œâ”€â”€ variables_shap.txt
â”œâ”€â”€ variables_stepwise.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales
â”‚   â”‚   â”œâ”€â”€ Actividades Economicas de Madrid.csv
â”‚   â”‚   â”œâ”€â”€ MadridActividades.csv
â”‚   â”‚   â”œâ”€â”€ RentaPOB.xlsx
â”‚   â”‚   â””â”€â”€ actividadeconomicamadrid.csv
â”‚   â”œâ”€â”€ processed/              # Datos procesados
â”‚   â”‚   â””â”€â”€ df_limpio.pkl
â”‚   â””â”€â”€ external/               # Fuentes externas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Pipeline principal
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Carga de datos
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py     # Limpieza y normalizaciÃ³n
â”‚   â”‚   â””â”€â”€ data_preprocessor.py # Preprocesamiento
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_selector.py  # SelecciÃ³n de variables (Boruta, RFECV, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_models.py     # Entrenamiento de 9 modelos
â”‚   â”‚   â””â”€â”€ model_evaluation.py # EvaluaciÃ³n y comparaciÃ³n
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # ConfiguraciÃ³n
â”‚       â””â”€â”€ helpers.py          # Utilidades
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Curvas ROC, matrices de confusiÃ³n, SHAP
â”‚   â”œâ”€â”€ logs/                   # Archivos de log
â”‚   â”‚   â””â”€â”€ madrid_prediction.log
â”‚   â””â”€â”€ reports/                # Reportes CSV y HTML
â”‚       â”œâ”€â”€ feature_selection_consensus.csv
â”‚       â”œâ”€â”€ model_comparison.csv
â”‚       â””â”€â”€ shap_importances.csv
â””â”€â”€ models/                     # Modelos entrenados y artefactos
    â”œâ”€â”€ decision_tree_model.pkl
    â”œâ”€â”€ knn_model.pkl
    â”œâ”€â”€ logistic_regression_model.pkl
    â”œâ”€â”€ mlp_model.pkl
    â”œâ”€â”€ random_forest_model.pkl
    â”œâ”€â”€ stacking_classifier_model.pkl
    â”œâ”€â”€ svm_model.pkl
    â”œâ”€â”€ voting_classifier_model.pkl
    â”œâ”€â”€ xgboost_model.pkl
    â”œâ”€â”€ scaler.joblib
    â”œâ”€â”€ selected_features_*.pkl  # Features seleccionadas
    â”œâ”€â”€ X_train.joblib
    â”œâ”€â”€ X_train_scaled.joblib
    â”œâ”€â”€ X_test.joblib
    â”œâ”€â”€ X_test_scaled.joblib
    â”œâ”€â”€ y_train.joblib
    â””â”€â”€ y_test.joblib
```

## InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.9+
- 16GB+ RAM (recomendado para dataset completo)
- Espacio en disco: 5GB+

### InstalaciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/alexandrobg/madrid-commercial-prediction.git
cd madrid-commercial-prediction

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con rutas personalizadas
```

### Datos Requeridos

Coloque los siguientes archivos en `data/raw/`:

```
data/raw/
â”œâ”€â”€ Actividades Economicas de Madrid.csv  # Datos del Ayuntamiento
â””â”€â”€ RentaPOB.xlsx                        # Datos socioeconÃ³micos
```

**Enlace a dataset principal**: [Google Drive](https://drive.google.com/file/d/17HAOjSxzSkesvHLXmwoyr__u_nAywIL9/view?usp=drive_link)

### EjecuciÃ³n

#### Pipeline Completo (Recomendado)
```bash
python -m src.main
```

#### EjecuciÃ³n Modular
```bash
# Solo procesamiento de datos
python -m src.data.data_preprocessor

# Solo entrenamiento de modelos
python -m src.models.train_models

# Solo evaluaciÃ³n
python -m src.models.model_evaluation
```

### Preprocesamiento de Datos

1. **Limpieza**: ImputaciÃ³n de coordenadas geogrÃ¡ficas, normalizaciÃ³n de texto, correcciÃ³n de inconsistencias
2. **IngenierÃ­a de Variables**: One-hot encoding, estandarizaciÃ³n Z-score, creaciÃ³n de variable objetivo binaria
3. **SelecciÃ³n de Variables**: 5 mÃ©todos comparados (Boruta seleccionado como Ã³ptimo)

### Modelos Implementados

- **Algoritmos Base**: RegresiÃ³n LogÃ­stica, Ãrboles de DecisiÃ³n, Random Forest, SVM, KNN, XGBoost, MLP
- **Ensambles**: VotingClassifier (soft voting), StackingClassifier
- **OptimizaciÃ³n**: GridSearchCV y RandomizedSearchCV con validaciÃ³n cruzada estratificada
- **ValidaciÃ³n**: DivisiÃ³n temporal (entrenamiento: 2020-2023, test: 2024)

### MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: Exactitud global
- **Precision/Recall**: Balance falsos positivos/negativos
- **F1-Score**: Media armÃ³nica precision-recall
- **AUC-ROC**: Capacidad discriminativa
- **Especificidad**: DetecciÃ³n de verdaderos negativos

## Aplicaciones PrÃ¡cticas

### Casos de Uso

- **PlanificaciÃ³n Urbana**: IdentificaciÃ³n de zonas comerciales en riesgo
- **PolÃ­tica PÃºblica**: FocalizaciÃ³n de ayudas y subvenciones
- **InversiÃ³n Privada**: EvaluaciÃ³n de ubicaciones comerciales
- **Transparencia**: Open data para ciudadanÃ­a y investigadores

### ImplementaciÃ³n Recomendada

1. **API Interna**: Despliegue como servicio REST para departamentos municipales
2. **Dashboard Interactivo**: VisualizaciÃ³n en tiempo real de predicciones
3. **Alertas AutomÃ¡ticas**: Sistema de notificaciones para zonas de alto riesgo
4. **Explicabilidad**: Reportes SHAP para justificar decisiones

## Testing y Calidad

```bash
# Ejecutar todas las pruebas
python -m pytest tests/ -v

# Pruebas especÃ­ficas por mÃ³dulo
python -m pytest tests/test_models/ -v
python -m pytest tests/test_data/ -v
python -m pytest tests/test_features/ -v
```

### Cobertura de Pruebas

- ValidaciÃ³n de carga de datos
- Pruebas de transformaciÃ³n y limpieza
- ValidaciÃ³n de modelos entrenados
- Tests de integraciÃ³n del pipeline completo

## Contribuciones

### Proceso de ContribuciÃ³n

1. Fork del proyecto
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -m 'DescripciÃ³n clara'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Abrir Pull Request con descripciÃ³n detallada

### EstÃ¡ndares de CÃ³digo

- PEP 8 para estilo de Python
- Docstrings en todas las funciones pÃºblicas
- Type hints cuando sea apropiado
- Tests unitarios para nueva funcionalidad

## InformaciÃ³n del Proyecto

### AutorÃ­a

**Alexandro BazÃ¡n Guardia**
MÃ¡ster en Ciencia de Datos e Inteligencia de Negocios
Universidad Complutense de Madrid

- **Email**: alexandro.bazan9712@gmail.com
- **LinkedIn**: [alexandrobg](https://www.linkedin.com/in/alexandrobg/)
- **GitHub**: [alexandrobg](https://github.com/alexandrobg)

### SupervisiÃ³n AcadÃ©mica

**Tutora**: BelÃ©n RodrÃ­guez-CÃ¡novas
Facultad de Estudios EstadÃ­sticos - Universidad Complutense de Madrid

### Agradecimientos

- Facultad de Estudios EstadÃ­sticos - UCM por el soporte acadÃ©mico
- Ayuntamiento de Madrid por el acceso a datos pÃºblicos
- Comunidad open source por las librerÃ­as utilizadas

## Licencia y CitaciÃ³n

### Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver archivo `LICENSE` para detalles completos.

### Cita AcadÃ©mica

Si utiliza este trabajo en investigaciÃ³n acadÃ©mica, por favor cite:

```bibtex
@mastersthesis{bazan2025madrid,
  title={PredicciÃ³n de la inactividad de locales comerciales en Madrid mediante tÃ©cnicas de Machine Learning},
  author={BazÃ¡n Guardia, Alexandro},
  year={2025},
  school={Universidad Complutense de Madrid},
  type={Trabajo de Fin de MÃ¡ster},
  url={https://github.com/alexandrobg/madrid-commercial-prediction}
}
```

### Referencias Principales

- Ayuntamiento de Madrid. (2025). *Actividades EconÃ³micas de Madrid* [Dataset]
- Breiman, L. (2001). Random forests. *Machine Learning*, 45(1), 5-32
- Lundberg, S., & Lee, S. (2017). A unified approach to interpreting model predictions. *NIPS*

## Roadmap y Desarrollo Futuro

### VersiÃ³n Actual (v1.0)
- âœ… Pipeline completo de ML
- âœ… 9 modelos comparados
- âœ… AnÃ¡lisis SHAP
- âœ… DocumentaciÃ³n completa

### PrÃ³ximas Versiones
- ğŸ”„ API REST para predicciones en tiempo real
- ğŸ”„ Dashboard web interactivo
- ğŸ”„ IntegraciÃ³n con datos en streaming
- ğŸ”„ Modelos de deep learning (LSTM, Transformer)
- ğŸ”„ AnÃ¡lisis de series temporales avanzado

---

**Status**: ProducciÃ³n | **Ãšltima actualizaciÃ³n**: Septiembre 2025 | **VersiÃ³n**: 1.0.0
