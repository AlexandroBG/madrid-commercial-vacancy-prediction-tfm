# Commercial Activity Prediction in Madrid | PredicciÃ³n de Actividad Comercial en Madrid

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Production-green.svg)](https://github.com/alexandrobg/madrid-commercial-prediction)

---

## English Version

### Executive Summary

This project implements a Machine Learning system to predict commercial establishment inactivity in Madrid, utilizing administrative data from Madrid City Council (2020-2024) enriched with socioeconomic indicators. The main model (MLP) achieves 88.48% accuracy and 0.854 AUC, providing a robust tool for decision-making in urban planning and commercial policy.

### Project Description

#### Context and Motivation

Madrid, as Spain's economic capital, concentrates over 60,000 commercial establishments that directly employ more than 305,000 people. However, events such as the COVID-19 pandemic and changes in consumption patterns have generated unequal commercial closures based on location and sector. This project addresses the need to anticipate these closures to optimize public policies and private investment decisions.

#### Technical Features

- **Dataset**: 8.3+ million historical records (2020-2024)
- **Variables**: Geolocation, CNAE classification, access type, per capita income, population
- **Methodology**: SEMMA (SAS Enterprise Miner) with temporal validation
- **Models**: 9 different algorithms with hyperparameter optimization
- **Interpretability**: SHAP analysis for model explainability

### Main Results

#### Model Performance (2024 Test Set)

| Model | AUC | F1-Score | Accuracy | Features |
|--------|-----|----------|----------|----------|
| **MLP** | **0.8540** | **0.9253** | **0.8848** | Best overall balance; selected for parsimony |
| VotingClassifier | 0.8541 | 0.9242 | 0.8828 | Robust ensemble (RF + XGB + MLP) |
| Random Forest | 0.8489 | 0.9250 | 0.8841 | High recall; interpretable |
| XGBoost | 0.8491 | 0.9151 | 0.8673 | Good AUC; conservative in specificity |
| Logistic Regression | 0.8475 | 0.9253 | 0.8848 | Solid and stable baseline |

#### Most Influential Variables (SHAP Analysis)

1. **desc_seccion_sin_actividad** â€” No activity indicator (negative impact)
2. **desc_tipo_acceso_local_puerta_calle** â€” Direct street access (positive impact)
3. **Renta_Media** â€” District median income (higher income â†’ greater activity)
4. **Total_Poblacion** â€” Neighborhood population (moderate positive impact)
5. **desc_seccion_hosteleria** â€” Hospitality sector presence (positive impact)

### Project Architecture

```
madrid-commercial-prediction/
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ TFM-Alexandro Bazan Guardia.pdf
â”œâ”€â”€ VERIFICATION.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ variables_boruta.txt
â”œâ”€â”€ variables_rfecv.txt
â”œâ”€â”€ variables_sbf.txt
â”œâ”€â”€ variables_shap.txt
â”œâ”€â”€ variables_stepwise.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original data
â”‚   â”‚   â”œâ”€â”€ Actividades Economicas de Madrid.csv
â”‚   â”‚   â”œâ”€â”€ MadridActividades.csv
â”‚   â”‚   â”œâ”€â”€ RentaPOB.xlsx
â”‚   â”‚   â””â”€â”€ actividadeconomicamadrid.csv
â”‚   â”œâ”€â”€ processed/              # Processed data
â”‚   â”‚   â””â”€â”€ df_limpio.pkl
â”‚   â””â”€â”€ external/               # External sources
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Main pipeline
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Data loading
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py     # Cleaning and normalization
â”‚   â”‚   â””â”€â”€ data_preprocessor.py # Preprocessing
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_selector.py  # Variable selection (Boruta, RFECV, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_models.py     # Training of 9 models
â”‚   â”‚   â””â”€â”€ model_evaluation.py # Evaluation and comparison
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Configuration
â”‚       â””â”€â”€ helpers.py          # Utilities
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # ROC curves, confusion matrices, SHAP
â”‚   â”œâ”€â”€ logs/                   # Log files
â”‚   â”‚   â””â”€â”€ madrid_prediction.log
â”‚   â””â”€â”€ reports/                # CSV and HTML reports
â”‚       â”œâ”€â”€ feature_selection_consensus.csv
â”‚       â”œâ”€â”€ model_comparison.csv
â”‚       â””â”€â”€ shap_importances.csv
â””â”€â”€ models/                     # Trained models and artifacts
    â”œâ”€â”€ decision_tree_model.pkl
    â”œâ”€â”€ knn_model.pkl
    â”œâ”€â”€ logistic_regression_model.pkl
    â”œâ”€â”€ mlp_model.pkl
    â”œâ”€â”€ random_forest_model.pkl
    â”œâ”€â”€ stacking_classifier_model.pkl
    â”œâ”€â”€ svm_model.pkl
    â”œâ”€â”€ voting_classifier_model.pkl
    â”œâ”€â”€ xgboost_model.pkl
    â”œâ”€â”€ scaler.joblib
    â”œâ”€â”€ selected_features_*.pkl  # Selected features
    â”œâ”€â”€ X_train.joblib
    â”œâ”€â”€ X_train_scaled.joblib
    â”œâ”€â”€ X_test.joblib
    â”œâ”€â”€ X_test_scaled.joblib
    â”œâ”€â”€ y_train.joblib
    â””â”€â”€ y_test.joblib
```

### Installation and Usage

#### Prerequisites

- Python 3.9+
- 16GB+ RAM (recommended for full dataset)
- Disk space: 5GB+

#### Installation

```bash
# 1. Clone repository
git clone https://github.com/alexandrobg/madrid-commercial-prediction.git
cd madrid-commercial-prediction

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment variables
cp .env.example .env
# Edit .env with custom paths
```

#### Required Data

The data required for this project consists of two main sources:

**1. Madrid Economic Activities Data**
**Link**: [Economic Activities of Madrid](https://drive.google.com/file/d/18VwmTOxIbtYH0jCHbaAlBx5lHU-ywuYt/view?usp=drive_link)

**Origin**: Monthly CSV files from Madrid City Council's open data portal (January 2020 - December 2024)

**2. Socioeconomic Data**
**Link**: [RentaPOB - Income and Population by Neighborhood](https://docs.google.com/spreadsheets/d/1iNgb0F5JdqcnIyjNU3ZsyBFVH1yP51PS/edit?usp=drive_link&ouid=106414683644608503271&rtpof=true&sd=true)

**Origin**: Madrid City Council Database with information disaggregated by neighborhood and year

#### Execution

**Complete Pipeline (Recommended)**
```bash
python -m src.main
```

**Modular Execution**
```bash
# Data processing only
python -m src.data.data_preprocessor

# Model training only
python -m src.models.train_models

# Evaluation only
python -m src.models.model_evaluation
```

### Practical Applications

#### Use Cases

- **Urban Planning**: Identification of at-risk commercial areas
- **Public Policy**: Targeting of aid and subsidies
- **Private Investment**: Evaluation of commercial locations
- **Transparency**: Open data for citizens and researchers

#### Recommended Implementation

1. **Internal API**: Deployment as REST service for municipal departments
2. **Interactive Dashboard**: Real-time prediction visualization
3. **Automatic Alerts**: Notification system for high-risk areas
4. **Explainability**: SHAP reports to justify decisions

### Testing and Quality

```bash
# Run all tests
python -m pytest tests/ -v

# Module-specific tests
python -m pytest tests/test_models/ -v
python -m pytest tests/test_data/ -v
python -m pytest tests/test_features/ -v
```

### Project Information

#### Authorship

**Alexandro BazÃ¡n Guardia**
Master in Data Science and Business Intelligence
Complutense University of Madrid

- **Email**: alexandro.bazan9712@gmail.com
- **LinkedIn**: [alexandrobg](https://www.linkedin.com/in/alexandrobg/)
- **GitHub**: [alexandrobg](https://github.com/alexandrobg)

#### Academic Supervision

**Supervisor**: BelÃ©n RodrÃ­guez-CÃ¡novas
Faculty of Statistical Studies - Complutense University of Madrid

### License and Citation

#### License

This project is licensed under the **MIT License**. See `LICENSE` file for complete details.

#### Academic Citation

If you use this work in academic research, please cite:

```bibtex
@mastersthesis{bazan2025madrid,
  title={Prediction of commercial establishment inactivity in Madrid using Machine Learning techniques},
  author={BazÃ¡n Guardia, Alexandro},
  year={2025},
  school={Complutense University of Madrid},
  type={Master's Thesis},
  url={https://github.com/alexandrobg/madrid-commercial-prediction}
}
```

---

## VersiÃ³n en EspaÃ±ol

### Resumen Ejecutivo

Este proyecto implementa un sistema de Machine Learning para predecir la inactividad de locales comerciales en Madrid, utilizando datos administrativos del Ayuntamiento de Madrid (2020-2024) enriquecidos con indicadores socioeconÃ³micos. El modelo principal (MLP) alcanza una precisiÃ³n del 88.48% y un AUC de 0.854, proporcionando una herramienta robusta para la toma de decisiones en planificaciÃ³n urbana y polÃ­tica comercial.

### DescripciÃ³n del Proyecto

#### Contexto y MotivaciÃ³n

Madrid, como capital econÃ³mica de EspaÃ±a, concentra mÃ¡s de 60,000 establecimientos comerciales que emplean directamente a mÃ¡s de 305,000 personas. Sin embargo, eventos como la pandemia COVID-19 y cambios en los patrones de consumo han generado cierres comerciales desiguales segÃºn ubicaciÃ³n y sector. Este proyecto aborda la necesidad de anticipar estos cierres para optimizar polÃ­ticas pÃºblicas y decisiones de inversiÃ³n privada.

#### CaracterÃ­sticas TÃ©cnicas

- **Dataset**: 8.3+ millones de registros histÃ³ricos (2020-2024)
- **Variables**: GeolocalizaciÃ³n, clasificaciÃ³n CNAE, tipo de acceso, renta per cÃ¡pita, poblaciÃ³n
- **MetodologÃ­a**: SEMMA (SAS Enterprise Miner) con validaciÃ³n temporal
- **Modelos**: 9 algoritmos diferentes con optimizaciÃ³n de hiperparÃ¡metros
- **Interpretabilidad**: AnÃ¡lisis SHAP para explicabilidad del modelo

### Resultados Principales

#### Rendimiento de Modelos (Conjunto de Test 2024)

| Modelo | AUC | F1-Score | Accuracy | CaracterÃ­sticas |
|--------|-----|----------|----------|----------------|
| **MLP** | **0.8540** | **0.9253** | **0.8848** | Mejor equilibrio global; seleccionado por parsimonia |
| VotingClassifier | 0.8541 | 0.9242 | 0.8828 | Ensamble robusto (RF + XGB + MLP) |
| Random Forest | 0.8489 | 0.9250 | 0.8841 | Alto recall; interpretable |
| XGBoost | 0.8491 | 0.9151 | 0.8673 | Buen AUC; conservador en especificidad |
| RegresiÃ³n LogÃ­stica | 0.8475 | 0.9253 | 0.8848 | Baseline sÃ³lido y estable |

#### Variables MÃ¡s Influyentes (AnÃ¡lisis SHAP)

1. **desc_seccion_sin_actividad** â€” Indicador de falta de actividad (impacto negativo)
2. **desc_tipo_acceso_local_puerta_calle** â€” Acceso directo desde calle (impacto positivo)
3. **Renta_Media** â€” Renta media del distrito (mayor renta â†’ mayor actividad)
4. **Total_Poblacion** â€” PoblaciÃ³n del barrio (impacto positivo moderado)
5. **desc_seccion_hosteleria** â€” Presencia del sector hostelerÃ­a (impacto positivo)

### Arquitectura del Proyecto

```
madrid-commercial-prediction/
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ TFM-Alexandro Bazan Guardia.pdf
â”œâ”€â”€ VERIFICATION.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ variables_boruta.txt
â”œâ”€â”€ variables_rfecv.txt
â”œâ”€â”€ variables_sbf.txt
â”œâ”€â”€ variables_shap.txt
â”œâ”€â”€ variables_stepwise.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales
â”‚   â”‚   â”œâ”€â”€ Actividades Economicas de Madrid.csv
â”‚   â”‚   â”œâ”€â”€ MadridActividades.csv
â”‚   â”‚   â”œâ”€â”€ RentaPOB.xlsx
â”‚   â”‚   â””â”€â”€ actividadeconomicamadrid.csv
â”‚   â”œâ”€â”€ processed/              # Datos procesados
â”‚   â”‚   â””â”€â”€ df_limpio.pkl
â”‚   â””â”€â”€ external/               # Fuentes externas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Pipeline principal
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Carga de datos
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py     # Limpieza y normalizaciÃ³n
â”‚   â”‚   â””â”€â”€ data_preprocessor.py # Preprocesamiento
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_selector.py  # SelecciÃ³n de variables (Boruta, RFECV, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_models.py     # Entrenamiento de 9 modelos
â”‚   â”‚   â””â”€â”€ model_evaluation.py # EvaluaciÃ³n y comparaciÃ³n
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # ConfiguraciÃ³n
â”‚       â””â”€â”€ helpers.py          # Utilidades
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Curvas ROC, matrices de confusiÃ³n, SHAP
â”‚   â”œâ”€â”€ logs/                   # Archivos de log
â”‚   â”‚   â””â”€â”€ madrid_prediction.log
â”‚   â””â”€â”€ reports/                # Reportes CSV y HTML
â”‚       â”œâ”€â”€ feature_selection_consensus.csv
â”‚       â”œâ”€â”€ model_comparison.csv
â”‚       â””â”€â”€ shap_importances.csv
â””â”€â”€ models/                     # Modelos entrenados y artefactos
    â”œâ”€â”€ decision_tree_model.pkl
    â”œâ”€â”€ knn_model.pkl
    â”œâ”€â”€ logistic_regression_model.pkl
    â”œâ”€â”€ mlp_model.pkl
    â”œâ”€â”€ random_forest_model.pkl
    â”œâ”€â”€ stacking_classifier_model.pkl
    â”œâ”€â”€ svm_model.pkl
    â”œâ”€â”€ voting_classifier_model.pkl
    â”œâ”€â”€ xgboost_model.pkl
    â”œâ”€â”€ scaler.joblib
    â”œâ”€â”€ selected_features_*.pkl  # Features seleccionadas
    â”œâ”€â”€ X_train.joblib
    â”œâ”€â”€ X_train_scaled.joblib
    â”œâ”€â”€ X_test.joblib
    â”œâ”€â”€ X_test_scaled.joblib
    â”œâ”€â”€ y_train.joblib
    â””â”€â”€ y_test.joblib
```

### InstalaciÃ³n y Uso

#### Prerrequisitos

- Python 3.9+
- 16GB+ RAM (recomendado para dataset completo)
- Espacio en disco: 5GB+

#### InstalaciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/alexandrobg/madrid-commercial-prediction.git
cd madrid-commercial-prediction

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con rutas personalizadas
```

#### Datos Requeridos

Los datos necesarios para este proyecto se componen de dos fuentes principales:

**1. Datos de Actividades EconÃ³micas de Madrid**
**Enlace**: [Actividades EconÃ³micas de Madrid](https://drive.google.com/file/d/18VwmTOxIbtYH0jCHbaAlBx5lHU-ywuYt/view?usp=drive_link)

**Origen**: Archivos CSV mensuales del portal de datos abiertos del Ayuntamiento de Madrid (enero 2020 - diciembre 2024)

**2. Datos SocioeconÃ³micos**
**Enlace**: [RentaPOB - Renta y PoblaciÃ³n por Barrio](https://docs.google.com/spreadsheets/d/1iNgb0F5JdqcnIyjNU3ZsyBFVH1yP51PS/edit?usp=drive_link&ouid=106414683644608503271&rtpof=true&sd=true)

**Origen**: Banco de Datos del Ayuntamiento de Madrid con informaciÃ³n desagregada por barrio y aÃ±o

#### EjecuciÃ³n

**Pipeline Completo (Recomendado)**
```bash
python -m src.main
```

**EjecuciÃ³n Modular**
```bash
# Solo procesamiento de datos
python -m src.data.data_preprocessor

# Solo entrenamiento de modelos
python -m src.models.train_models

# Solo evaluaciÃ³n
python -m src.models.model_evaluation
```

### Aplicaciones PrÃ¡cticas

#### Casos de Uso

- **PlanificaciÃ³n Urbana**: IdentificaciÃ³n de zonas comerciales en riesgo
- **PolÃ­tica PÃºblica**: FocalizaciÃ³n de ayudas y subvenciones
- **InversiÃ³n Privada**: EvaluaciÃ³n de ubicaciones comerciales
- **Transparencia**: Open data para ciudadanÃ­a e investigadores

#### ImplementaciÃ³n Recomendada

1. **API Interna**: Despliegue como servicio REST para departamentos municipales
2. **Dashboard Interactivo**: VisualizaciÃ³n en tiempo real de predicciones
3. **Alertas AutomÃ¡ticas**: Sistema de notificaciones para zonas de alto riesgo
4. **Explicabilidad**: Reportes SHAP para justificar decisiones

### Testing y Calidad

```bash
# Ejecutar todas las pruebas
python -m pytest tests/ -v

# Pruebas especÃ­ficas por mÃ³dulo
python -m pytest tests/test_models/ -v
python -m pytest tests/test_data/ -v
python -m pytest tests/test_features/ -v
```

### InformaciÃ³n del Proyecto

#### AutorÃ­a

**Alexandro BazÃ¡n Guardia**
MÃ¡ster en Ciencia de Datos e Inteligencia de Negocios
Universidad Complutense de Madrid

- **Email**: alexandro.bazan9712@gmail.com
- **LinkedIn**: [alexandrobg](https://www.linkedin.com/in/alexandrobg/)
- **GitHub**: [alexandrobg](https://github.com/alexandrobg)

#### SupervisiÃ³n AcadÃ©mica

**Tutora**: BelÃ©n RodrÃ­guez-CÃ¡novas
Facultad de Estudios EstadÃ­sticos - Universidad Complutense de Madrid

### Licencia y CitaciÃ³n

#### Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver archivo `LICENSE` para detalles completos.

#### Cita AcadÃ©mica

Si utiliza este trabajo en investigaciÃ³n acadÃ©mica, por favor cite:

```bibtex
@mastersthesis{bazan2025madrid,
  title={PredicciÃ³n de la inactividad de locales comerciales en Madrid mediante tÃ©cnicas de Machine Learning},
  author={BazÃ¡n Guardia, Alexandro},
  year={2025},
  school={Universidad Complutense de Madrid},
  type={Trabajo de Fin de MÃ¡ster},
  url={https://github.com/alexandrobg/madrid-commercial-prediction}
}
```

### Agradecimientos

- Facultad de Estudios EstadÃ­sticos - UCM por el soporte acadÃ©mico
- Ayuntamiento de Madrid por el acceso a datos pÃºblicos
- Comunidad open source por las librerÃ­as utilizadas

### Roadmap y Desarrollo Futuro

#### VersiÃ³n Actual (v1.0)
- âœ… Pipeline completo de ML
- âœ… 9 modelos comparados
- âœ… AnÃ¡lisis SHAP
- âœ… DocumentaciÃ³n completa

#### PrÃ³ximas Versiones
- ðŸ”„ API REST para predicciones en tiempo real
- ðŸ”„ Dashboard web interactivo
- ðŸ”„ IntegraciÃ³n con datos en streaming
- ðŸ”„ Modelos de deep learning (LSTM, Transformer)
- ðŸ”„ AnÃ¡lisis de series temporales avanzado

---

**Status**: ProducciÃ³n | **Ãšltima actualizaciÃ³n**: Septiembre 2025 | **VersiÃ³n**: 1.0.0
